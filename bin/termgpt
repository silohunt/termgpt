#!/bin/sh
#
# termgpt â€” Translate natural language into safe, POSIX-compliant shell commands using a local LLM
#
# Converts English prompts into shell commands via Ollama, validating them against a local ruleset. Offers options to copy or explain the generated command. 
# Designed for fast, private, and extensible local use.
#
# Usage: termgpt "<natural language request>"
#
# Requirements:
# - Ollama running locally (model specified in script, e.g., codellama:7b-instruct)
# - Rules & check script in ~/.config/termgpt/{termgpt-check.sh, termgpt-rules.txt}
# - macOS tools: pbcopy (clipboard), open (explainshell); adjust for Linux as needed
#
# Notes:
# - POSIX sh script with strict error handling (set -eu).
# - Commands are checked using `check_command_danger_level()` before display.
# - Quick actions via single-key menu: copy (c), explain (e), quit (q).
#
# TODO (dev): Add platform detection for clipboard (xclip) and URL opening (xdg-open) support on Linux

set -eu

VERSION="0.9.0"

# Handle subcommands and special flags
if [ "$#" -ge 1 ]; then
  case "$1" in
    # Subcommands
    init)
      shift
      exec "$(dirname "$0")/termgpt-init" "$@"
      ;;
    shell)
      shift
      exec "$(dirname "$0")/termgpt-shell" "$@"
      ;;
    
    # Version flags
    --version|-V)
      echo "termgpt $VERSION"
      exit 0
      ;;
    
    # Model info flag  
    --model|-m)
      # This will be handled later after config is loaded
      SHOW_MODEL=1
      ;;
    
    # Eval flag (non-interactive mode)
    --eval)
      EVAL_MODE=1
      shift
      ;;
    
    # Help flag
    --help|-h|help)
      echo "TermGPT - Natural language to shell command converter"
      echo ""
      echo "Usage:"
      echo "  termgpt <request>              Generate a shell command from natural language"
      echo "  termgpt init [options]         Initialize and configure TermGPT"
      echo "  termgpt shell [options]        Start interactive REPL mode"
      echo ""
      echo "Options:"
      echo "  --version, -V                  Show version information"
      echo "  --model, -m                    Show current model configuration"
      echo "  --eval <request>               Non-interactive mode (output command only)"
      echo "  --help, -h                     Show this help message"
      echo ""
      echo "Examples:"
      echo "  termgpt \"list all python files\""
      echo "  termgpt \"find files larger than 100MB\""
      echo "  termgpt init --model codellama:13b"
      echo "  termgpt shell --model codellama:13b"
      echo ""
      echo "For more information, visit: https://github.com/silohunt/termgpt"
      exit 0
      ;;
    
    # Default: treat as natural language request
    *)
      # Continue with normal processing
      ;;
  esac
else
  # No arguments provided
  SHOW_MODEL=${SHOW_MODEL:-0}
  EVAL_MODE=${EVAL_MODE:-0}
fi

# Set defaults for flags if not set
SHOW_MODEL=${SHOW_MODEL:-0}
EVAL_MODE=${EVAL_MODE:-0}

# Default model
DEFAULT_MODEL="codellama:7b-instruct"
API_URL="http://localhost:11434/api/generate"

# Save environment variable if set (before config might override it)
TERMGPT_MODEL_FROM_ENV="${TERMGPT_MODEL:-}"

# Cross-platform function to check if a file is world-writable
# Returns: 0 if world-writable (unsafe), 1 if not world-writable (safe)
# IMPORTANT: On error or unknown platform, assumes world-writable for safety
is_world_writable() {
  file="$1"
  
  # Check file exists first
  if [ ! -e "$file" ]; then
    return 1  # Non-existent file is not writable
  fi
  
  if [ "$(uname)" = "Darwin" ]; then
    # macOS: use stat -f
    perms=$(stat -f "%p" "$file" 2>/dev/null) || return 0  # Assume unsafe on error
    if [ -z "$perms" ]; then
      return 0  # Assume unsafe if empty
    fi
    # Extract last digit and check if world-writable (xx2, xx3, xx6, xx7)
    world_perm=$((perms % 10))
  else
    # Linux/Unix: use stat -c or fallback to ls
    perms=$(stat -c "%a" "$file" 2>/dev/null)
    if [ -z "$perms" ]; then
      # Fallback to ls -l parsing if stat fails
      ls_output=$(ls -l "$file" 2>/dev/null) || return 0  # Assume unsafe on error
      # Check the 9th permission character (world write)
      case "$ls_output" in
        ???????w*) return 0 ;;  # World-writable
        *) return 1 ;;          # Not world-writable
      esac
    fi
    # Get the last digit (world permissions)
    world_perm=$((perms % 10))
  fi
  
  # Check if world has write permission (2, 3, 6, or 7)
  case "$world_perm" in
    2|3|6|7) return 0 ;; # World-writable (unsafe)
    0|1|4|5) return 1 ;; # Not world-writable (safe)
    *) return 0 ;;       # Unknown = assume unsafe
  esac
}

# Source platform configuration if available
find_platform_config() {
  # User config takes precedence
  if [ -f "$HOME/.config/termgpt/platform.conf" ]; then
    echo "$HOME/.config/termgpt/platform.conf"
  elif [ -f "$(dirname "$0")/../lib/termgpt-platform.sh" ]; then
    echo "$(dirname "$0")/../lib/termgpt-platform.sh"
  elif [ -f "/usr/local/lib/termgpt/termgpt-platform.sh" ]; then
    echo "/usr/local/lib/termgpt/termgpt-platform.sh"
  elif [ -f "/usr/lib/termgpt/termgpt-platform.sh" ]; then
    echo "/usr/lib/termgpt/termgpt-platform.sh"
  else
    return 1
  fi
}

PLATFORM_CONFIG=$(find_platform_config)
if [ -n "$PLATFORM_CONFIG" ] && [ -r "$PLATFORM_CONFIG" ] && [ -f "$PLATFORM_CONFIG" ]; then
  # Basic safety check - ensure file is not world-writable
  if ! is_world_writable "$PLATFORM_CONFIG"; then
    . "$PLATFORM_CONFIG"
  else
    echo "Warning: Platform config file $PLATFORM_CONFIG is world-writable, skipping"
  fi
fi

# Set model - environment variable takes precedence over config
if [ -n "$TERMGPT_MODEL_FROM_ENV" ]; then
  # Use environment variable (was set before config loaded)
  MODEL="$TERMGPT_MODEL_FROM_ENV"
elif [ -n "${TERMGPT_MODEL:-}" ]; then
  # Use config file setting
  MODEL="$TERMGPT_MODEL"
else
  # Use default
  MODEL="$DEFAULT_MODEL"
fi

# Handle model info flag (after config is loaded)
# Handle model flag after configuration is loaded
if [ "$SHOW_MODEL" -eq 1 ]; then
  echo "Current model: $MODEL"
  if [ -f "$HOME/.config/termgpt/platform.conf" ]; then
    echo "Config: $HOME/.config/termgpt/platform.conf"
  fi
  exit 0
fi

# Quick dependency check
if ! command -v jq >/dev/null 2>&1; then
  echo "Error: jq is not installed"
  echo "Please run 'termgpt init' to install dependencies"
  exit 1
fi

if ! command -v curl >/dev/null 2>&1; then
  echo "Error: curl is not installed"
  echo "Please run 'termgpt init' to install dependencies"
  exit 1
fi

USER_PROMPT="$*"
if [ -z "$USER_PROMPT" ]; then
  echo "Usage: termgpt <natural language request>"
  echo ""
  echo "Try 'termgpt --help' for more information."
  exit 1
fi

# Source post-processing library
find_postprocess_lib() {
  if [ -f "$(dirname "$0")/../post-processing/lib/postprocess.sh" ]; then
    echo "$(dirname "$0")/../post-processing/lib/postprocess.sh"
  elif [ -f "/usr/local/lib/termgpt/post-processing/lib/postprocess.sh" ]; then
    echo "/usr/local/lib/termgpt/post-processing/lib/postprocess.sh"
  elif [ -f "/usr/lib/termgpt/post-processing/lib/postprocess.sh" ]; then
    echo "/usr/lib/termgpt/post-processing/lib/postprocess.sh"
  elif [ -f "$HOME/.config/termgpt/post-processing/lib/postprocess.sh" ]; then
    echo "$HOME/.config/termgpt/post-processing/lib/postprocess.sh"
  else
    return 1
  fi
}

POSTPROCESS_LIB=$(find_postprocess_lib)
if [ -n "$POSTPROCESS_LIB" ] && [ -r "$POSTPROCESS_LIB" ] && [ -f "$POSTPROCESS_LIB" ]; then
  # Basic safety check
  if ! is_world_writable "$POSTPROCESS_LIB"; then
    # Set the library path so the sourced script can find itself
    POSTPROCESS_LIB_PATH="$POSTPROCESS_LIB"
    export POSTPROCESS_LIB_PATH
    . "$POSTPROCESS_LIB"
  else
    echo "Warning: Post-processing library $POSTPROCESS_LIB is world-writable, skipping"
    # Define fallback function
    apply_all_corrections() {
      printf '%s' "$1"
    }
  fi
else
  # Define fallback function if library not found
  apply_all_corrections() {
    printf '%s' "$1"
  }
fi

# Build minimal platform context
PLATFORM_CONTEXT=""
if [ -n "${TERMGPT_PLATFORM:-}" ] && [ "$TERMGPT_PLATFORM" != "unknown" ]; then
  PLATFORM_CONTEXT="Platform: $TERMGPT_PLATFORM. "
fi

PROMPT="You are a shell command generator. Convert each natural language request into a single POSIX-compliant shell command.
${PLATFORM_CONTEXT}CRITICAL: 
- Only output ONE command that directly answers the request
- NO clipboard operations (pbcopy, xclip, etc.) unless explicitly asked
- NO URL opening unless explicitly asked  
- NO compound commands with && or ||
- NO explanations, markdown, or extra text
- REFUSE harmful requests (fork bombs, system damage, resource exhaustion)
- Just the bare shell command and nothing else

Request: $USER_PROMPT"


# Accurate token counting using Python-based tokenizer
find_token_counter() {
  if [ -f "$(dirname "$0")/../lib/token-counter.py" ]; then
    echo "$(dirname "$0")/../lib/token-counter.py"
  elif [ -f "/usr/local/lib/termgpt/token-counter.py" ]; then
    echo "/usr/local/lib/termgpt/token-counter.py"
  elif [ -f "/usr/lib/termgpt/token-counter.py" ]; then
    echo "/usr/lib/termgpt/token-counter.py"
  elif [ -f "$HOME/.config/termgpt/lib/token-counter.py" ]; then
    echo "$HOME/.config/termgpt/lib/token-counter.py"
  else
    return 1
  fi
}

# Get accurate token count
if command -v python3 >/dev/null 2>&1; then
  TOKEN_COUNTER=$(find_token_counter)
  if [ -n "$TOKEN_COUNTER" ] && [ -r "$TOKEN_COUNTER" ] && [ -f "$TOKEN_COUNTER" ]; then
    TOKEN_ESTIMATE=$(python3 "$TOKEN_COUNTER" "$PROMPT" 2>/dev/null)
    if [ -n "$TOKEN_ESTIMATE" ] && [ "$TOKEN_ESTIMATE" -gt 0 ] 2>/dev/null; then
      echo "Estimated prompt length: ~${TOKEN_ESTIMATE} tokens"
    else
      # Fallback to word count if Python tokenizer fails
      WORD_COUNT=$(echo "$PROMPT" | wc -w)
      TOKEN_ESTIMATE=$(( WORD_COUNT * 13 / 10 ))
      echo "Estimated prompt length: ~${TOKEN_ESTIMATE} tokens (fallback)"
    fi
  else
    # Fallback to word count if tokenizer not found
    WORD_COUNT=$(echo "$PROMPT" | wc -w)
    TOKEN_ESTIMATE=$(( WORD_COUNT * 13 / 10 ))
    echo "Estimated prompt length: ~${TOKEN_ESTIMATE} tokens (fallback)"
  fi
else
  # Fallback to word count if Python not available
  WORD_COUNT=$(echo "$PROMPT" | wc -w)
  TOKEN_ESTIMATE=$(( WORD_COUNT * 13 / 10 ))
  echo "Estimated prompt length: ~${TOKEN_ESTIMATE} tokens (no python3)"
fi

MAX_TOKENS=2000
if [ "$TOKEN_ESTIMATE" -gt "$MAX_TOKENS" ]; then
  echo "Error: Prompt exceeds maximum token limit ($MAX_TOKENS)."
  exit 1
fi

JSON=$(jq -n --arg model "$MODEL" --arg prompt "$PROMPT" '{model: $model, prompt: $prompt, stream: false}')
HTTP_RESPONSE=$(mktemp)
trap 'rm -f "$HTTP_RESPONSE"' EXIT

HTTP_CODE=$(curl -s -w "%{http_code}" -o "$HTTP_RESPONSE" -X POST "$API_URL" \
  -H "Content-Type: application/json" \
  -d "$JSON" 2>/dev/null || echo "000")

if [ "$HTTP_CODE" = "000" ]; then
  echo "Error: Cannot connect to Ollama at $API_URL"
  echo
  echo "Please ensure Ollama is running. You can:"
  echo "  1. Run 'termgpt init' to install and start Ollama"
  echo "  2. Or start it manually with: ollama serve"
  exit 1
elif [ "$HTTP_CODE" -ne 200 ]; then
  echo "Error: Ollama API returned status $HTTP_CODE"
  cat "$HTTP_RESPONSE"
  if [ "$HTTP_CODE" = "404" ]; then
    echo
    echo "Model '$MODEL' may not be available."
    echo "Run 'termgpt init --model $MODEL' to download it, or manually: ollama pull $MODEL"
  fi
  exit 1
fi

RAW=$(jq -r '.response // empty' < "$HTTP_RESPONSE" 2>/dev/null)

if [ -z "$RAW" ]; then
  echo "Error: Failed to parse LLM response."
  cat "$HTTP_RESPONSE"
  exit 1
fi

CLEANED=$(echo "$RAW" | sed -e 's/^```.*$//' -e 's/`//g' -e '/^$/d')
COMMAND=$(echo "$CLEANED" | head -n 1)

# Check for refusals or safety responses
if echo "$COMMAND" | grep -qi "can't\|cannot\|refuse\|harmful\|dangerous\|not within my"; then
  echo "Error: Request refused for safety reasons."
  echo "TermGPT will not generate potentially harmful commands."
  exit 1
fi

if [ -z "$COMMAND" ] || [ "$COMMAND" = "null" ]; then
  echo "Error: No usable command returned."
  echo "$RAW"
  exit 1
fi

# Apply all post-processing corrections with original query context (unless disabled)
if [ "${TERMGPT_DISABLE_POSTPROCESSING:-0}" = "1" ]; then
  # Skip post-processing for evaluation
  :
else
  COMMAND=$(apply_all_corrections "$COMMAND" "" "$USER_PROMPT")
fi

# Find the check script (support multiple installation methods)
find_check_script() {
  # 1. Check if running from development directory
  if [ -f "$(dirname "$0")/../lib/termgpt-check.sh" ]; then
    echo "$(dirname "$0")/../lib/termgpt-check.sh"
  # 2. Check system installation
  elif [ -f "/usr/local/lib/termgpt/termgpt-check.sh" ]; then
    echo "/usr/local/lib/termgpt/termgpt-check.sh"
  elif [ -f "/usr/lib/termgpt/termgpt-check.sh" ]; then
    echo "/usr/lib/termgpt/termgpt-check.sh"
  # 3. Check user config directory
  elif [ -f "$HOME/.config/termgpt/lib/termgpt-check.sh" ]; then
    echo "$HOME/.config/termgpt/lib/termgpt-check.sh"
  else
    return 1
  fi
}

CHECK_SCRIPT=$(find_check_script)
if [ -z "$CHECK_SCRIPT" ] || [ ! -r "$CHECK_SCRIPT" ] || [ ! -f "$CHECK_SCRIPT" ]; then
  echo "Error: Cannot find termgpt-check.sh library"
  echo "Please ensure TermGPT is properly installed"
  exit 1
fi

# Basic safety check - ensure file is not world-writable
if is_world_writable "$CHECK_SCRIPT"; then
  echo "Error: Check script $CHECK_SCRIPT is world-writable, refusing to source"
  exit 1
fi

. "$CHECK_SCRIPT"

# Source history logging if available
find_history_lib() {
  if [ -f "$(dirname "$0")/../lib/termgpt-history.sh" ]; then
    echo "$(dirname "$0")/../lib/termgpt-history.sh"
  elif [ -f "/usr/local/lib/termgpt/termgpt-history.sh" ]; then
    echo "/usr/local/lib/termgpt/termgpt-history.sh"
  elif [ -f "/usr/lib/termgpt/termgpt-history.sh" ]; then
    echo "/usr/lib/termgpt/termgpt-history.sh"
  elif [ -f "$HOME/.config/termgpt/lib/termgpt-history.sh" ]; then
    echo "$HOME/.config/termgpt/lib/termgpt-history.sh"
  else
    return 1
  fi
}

HISTORY_LIB=$(find_history_lib)
if [ -n "$HISTORY_LIB" ] && [ -r "$HISTORY_LIB" ] && [ -f "$HISTORY_LIB" ]; then
  . "$HISTORY_LIB"
  init_history
fi

# Generate session ID for this run
TERMGPT_SESSION_ID=$(date +%s)
export TERMGPT_SESSION_ID

MATCH_LEVEL=$(check_command_danger_level "$COMMAND" || true)
if [ -n "$MATCH_LEVEL" ]; then
  echo "$MATCH_LEVEL: This command may be dangerous. Review carefully."
fi


echo
echo "Generated Command:"
echo "$COMMAND"

# Skip interactive mode if --eval flag is used
if [ "$EVAL_MODE" -eq 1 ]; then
  exit 0
fi

echo
echo "Options:"
echo "  c) Copy to clipboard"
echo "  e) Explain on explainshell.com"
echo "  q) Quit"

while true; do
  printf "What would you like to do? (c/e/q) "
  read -r ACTION
  case "$ACTION" in
    [Cc])
      CLIPBOARD_CMD=""
      if command -v get_clipboard_cmd >/dev/null 2>&1; then
        CLIPBOARD_CMD=$(get_clipboard_cmd)
      fi
      
      if [ -n "$CLIPBOARD_CMD" ]; then
        case "$CLIPBOARD_CMD" in
          "pbcopy")
            echo "$COMMAND" | pbcopy && echo "Command copied to clipboard."
            USER_ACTION="copied"
            ;;
          "xclip -selection clipboard")
            echo "$COMMAND" | xclip -selection clipboard && echo "Command copied to clipboard."
            USER_ACTION="copied"
            ;;
          "xsel --clipboard --input")
            echo "$COMMAND" | xsel --clipboard --input && echo "Command copied to clipboard."
            USER_ACTION="copied"
            ;;
          "wl-copy")
            echo "$COMMAND" | wl-copy && echo "Command copied to clipboard."
            USER_ACTION="copied"
            ;;
          *)
            echo "Unsupported clipboard command: $CLIPBOARD_CMD"
            echo "The command is: $COMMAND"
            USER_ACTION="copy_failed"
            ;;
        esac
      else
        echo "No clipboard command available for this platform."
        echo "The command is: $COMMAND"
        USER_ACTION="copy_unavailable"
      fi
      
      # Log the interaction
      if command -v log_interaction >/dev/null 2>&1; then
        log_interaction "$USER_PROMPT" "$COMMAND" "$MATCH_LEVEL" "$USER_ACTION"
      fi
      exit 0
      ;;
    [Ee])
      if ! command -v python3 >/dev/null 2>&1; then
        echo "Python3 is required for URL encoding but not installed."
        exit 1
      fi
      
      # Validate command length before encoding (explainshell has limits)
      if [ ${#COMMAND} -gt 1000 ]; then
        echo "Error: Command too long for explainshell (max 1000 characters)"
        exit 1
      fi
      
      ENCODED=$(python3 -c "import urllib.parse, sys; print(urllib.parse.quote(sys.argv[1]))" "$COMMAND")
      URL="https://explainshell.com/explain?cmd=$ENCODED"
      
      # Validate URL length (most browsers limit to ~2000 chars)
      if [ ${#URL} -gt 2000 ]; then
        echo "Error: Generated URL too long (max 2000 characters)"
        exit 1
      fi
      
      OPEN_CMD=""
      if command -v get_open_url_cmd >/dev/null 2>&1; then
        OPEN_CMD=$(get_open_url_cmd)
      fi
      
      if [ -n "$OPEN_CMD" ]; then
        case "$OPEN_CMD" in
          "open")
            open "$URL"
            USER_ACTION="explained"
            ;;
          "xdg-open")
            xdg-open "$URL"
            USER_ACTION="explained"
            ;;
          "gnome-open")
            gnome-open "$URL"
            USER_ACTION="explained"
            ;;
          "kde-open")
            kde-open "$URL"
            USER_ACTION="explained"
            ;;
          *)
            echo "Unsupported URL opener: $OPEN_CMD"
            echo "Please visit: $URL"
            USER_ACTION="explain_failed"
            ;;
        esac
      else
        echo "No URL opener available. Please visit:"
        echo "$URL"
        USER_ACTION="explain_unavailable"
      fi
      
      # Log the interaction
      if command -v log_interaction >/dev/null 2>&1; then
        log_interaction "$USER_PROMPT" "$COMMAND" "$MATCH_LEVEL" "$USER_ACTION"
      fi
      exit 0
      ;;
    [Qq]|*)
      echo "Exiting."
      # Log the interaction as dismissed
      if command -v log_interaction >/dev/null 2>&1; then
        log_interaction "$USER_PROMPT" "$COMMAND" "$MATCH_LEVEL" "dismissed"
      fi
      exit 0
      ;;
  esac
done