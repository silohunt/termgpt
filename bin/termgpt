#!/usr/bin/env zsh
#
# termgpt â€” Translate natural language into safe, POSIX-compliant shell commands using a local LLM
#
# Converts English prompts into shell commands via Ollama, validating them against a local ruleset. Offers options to copy or explain the generated command. 
# Designed for fast, private, and extensible local use.
#
# Usage: termgpt "<natural language request>"
#
# Requirements:
# - Ollama running locally (model specified in script, e.g., codellama:7b-instruct)
# - Rules & check script in ~/.config/termgpt/{termgpt-check.sh, termgpt-rules.txt}
# - macOS tools: pbcopy (clipboard), open (explainshell); adjust for Linux as needed
#
# Notes:
# - Zsh script with strict error handling (set -euo pipefail).
# - Commands are checked using `check_command_danger_level()` before display.
# - Quick actions via single-key menu: copy [c], explain [e], quit [q].
#
# TODO (dev): Add platform detection for clipboard (xclip) and URL opening (xdg-open) support on Linux

set -euo pipefail

MODEL="codellama:7b-instruct"
API_URL="http://localhost:11434/api/generate"

USER_PROMPT="$*"
if [[ -z "$USER_PROMPT" ]]; then
  echo "Usage: termgpt <natural language request>"
  exit 1
fi

PROMPT="You are a shell command generator. Convert each natural language request into a single POSIX-compliant shell command.
Only output the command with no extra text, explanations, markdown, or code fences.
Request: $USER_PROMPT"

WORD_COUNT=$(echo "$PROMPT" | wc -w)
TOKEN_ESTIMATE=$(( WORD_COUNT * 13 / 10 ))
echo "Estimated prompt length: ~${TOKEN_ESTIMATE} tokens"

MAX_TOKENS=2000
if (( TOKEN_ESTIMATE > MAX_TOKENS )); then
  echo "Error: Prompt exceeds maximum token limit ($MAX_TOKENS)."
  exit 1
fi

JSON=$(jq -n --arg model "$MODEL" --arg prompt "$PROMPT" '{model: $model, prompt: $prompt, stream: false}')
HTTP_RESPONSE=$(mktemp)
trap 'rm -f "$HTTP_RESPONSE"' EXIT

HTTP_CODE=$(curl -s -w "%{http_code}" -o "$HTTP_RESPONSE" -X POST "$API_URL" \
  -H "Content-Type: application/json" \
  -d "$JSON")

if [[ "$HTTP_CODE" -ne 200 ]]; then
  echo "Error: Ollama API returned status $HTTP_CODE"
  cat "$HTTP_RESPONSE"
  exit 1
fi

RAW=$(jq -r '.response // empty' < "$HTTP_RESPONSE" 2>/dev/null)

if [[ -z "$RAW" ]]; then
  echo "Error: Failed to parse LLM response."
  cat "$HTTP_RESPONSE"
  exit 1
fi

CLEANED=$(echo "$RAW" | sed -e 's/^```.*$//' -e 's/`//g' -e '/^$/d')
COMMAND=$(echo "$CLEANED" | head -n 1)

if [[ -z "$COMMAND" || "$COMMAND" == "null" ]]; then
  echo "Error: No usable command returned."
  echo "$RAW"
  exit 1
fi

# Securely source the command check script
CHECK_SCRIPT="$HOME/.config/termgpt/lib/termgpt-check.sh"
if [[ ! -f "$CHECK_SCRIPT" || ! -O "$CHECK_SCRIPT" || ! -r "$CHECK_SCRIPT" ]]; then
  echo "Error: Invalid or unsafe check script: $CHECK_SCRIPT"
  exit 1
fi
source "$CHECK_SCRIPT"

MATCH_LEVEL=$(check_command_danger_level "$COMMAND" || true)
if [[ -n "$MATCH_LEVEL" ]]; then
  echo "$MATCH_LEVEL: This command may be dangerous. Review carefully."
fi


echo
echo "Generated Command:"
echo "$COMMAND"
echo
echo "Options:"
echo "  [c] Copy to clipboard"
echo "  [e] Explain on explainshell.com"
echo "  [q] Quit"

while true; do
  read -r "ACTION?What would you like to do? [c/e/q] "
  case "$ACTION" in
    [Cc])
      if command -v pbcopy &>/dev/null; then
        echo "$COMMAND" | pbcopy && echo "Command copied to clipboard."
      else
        echo "Clipboard command 'pbcopy' not found."
      fi
      exit 0
      ;;
    [Ee])
      ENCODED=$(python3 -c "import urllib.parse, sys; print(urllib.parse.quote(sys.argv[1]))" "$COMMAND")
      open "https://explainshell.com/explain?cmd=$ENCODED"
      exit 0
      ;;
    [Qq]|*)
      echo "Exiting."
      exit 0
      ;;
  esac
done